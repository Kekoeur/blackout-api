/**
 * Script de test pour vÃ©rifier que NSFW.js fonctionne correctement
 */
require('dotenv').config();
const tf = require('@tensorflow/tfjs');
require('@tensorflow/tfjs-backend-cpu');
const nsfwjs = require('nsfwjs');
const { createCanvas, loadImage } = require('canvas');

async function testModeration() {
  console.log('ğŸš€ Test de modÃ©ration NSFW.js\n');

  try {
    // 1. Initialiser TensorFlow backend
    console.log('ğŸ“¦ Initialisation TensorFlow.js backend CPU...');
    await tf.setBackend('cpu');
    await tf.ready();
    console.log('âœ… Backend CPU prÃªt\n');

    // 2. Charger le modÃ¨le NSFW.js
    console.log('ğŸ“¦ Chargement du modÃ¨le NSFW.js (peut prendre ~30s au premier dÃ©marrage)...');
    const model = await nsfwjs.load();
    console.log('âœ… ModÃ¨le NSFW.js chargÃ©\n');

    // 3. Test avec une image de test (URL publique safe)
    const testImageUrl = 'https://images.unsplash.com/photo-1517849845537-4d257902454a?w=400';
    console.log(`ğŸ–¼ï¸  Test avec image: ${testImageUrl}`);

    const img = await loadImage(testImageUrl);
    console.log(`âœ… Image chargÃ©e: ${img.width}x${img.height}px\n`);

    // CrÃ©er canvas Ã  partir de l'image
    const canvas = createCanvas(img.width, img.height);
    const ctx = canvas.getContext('2d');
    ctx.drawImage(img, 0, 0);

    // 4. Classification
    console.log('ğŸ” Classification en cours...');
    const predictions = await model.classify(canvas);

    console.log('ğŸ“Š RÃ©sultats:\n');
    predictions.forEach(pred => {
      const percent = (pred.probability * 100).toFixed(2);
      const bar = 'â–ˆ'.repeat(Math.floor(pred.probability * 50));
      console.log(`  ${pred.className.padEnd(10)} ${percent.padStart(6)}%  ${bar}`);
    });

    // 5. Calcul des scores
    const pornScore = predictions.find(p => p.className === 'Porn')?.probability || 0;
    const hentaiScore = predictions.find(p => p.className === 'Hentai')?.probability || 0;
    const sexyScore = predictions.find(p => p.className === 'Sexy')?.probability || 0;
    const neutralScore = predictions.find(p => p.className === 'Neutral')?.probability || 0;

    const adultScore = (pornScore + hentaiScore) * 100;
    const racyScore = sexyScore * 100;

    console.log('\nğŸ“ˆ Scores calculÃ©s:');
    console.log(`  Adult content: ${adultScore.toFixed(1)}%`);
    console.log(`  Racy content:  ${racyScore.toFixed(1)}%`);
    console.log(`  Neutral:       ${(neutralScore * 100).toFixed(1)}%`);

    // 6. DÃ©cision de modÃ©ration
    const ADULT_REJECT_THRESHOLD = 60;
    const ADULT_REVIEW_THRESHOLD = 30;
    const RACY_REVIEW_THRESHOLD = 50;

    let status;
    if (adultScore > ADULT_REJECT_THRESHOLD) {
      status = 'âŒ REJECTED - Contenu explicite dÃ©tectÃ©';
    } else if (adultScore > ADULT_REVIEW_THRESHOLD || racyScore > RACY_REVIEW_THRESHOLD) {
      status = 'âš ï¸  NEEDS_REVIEW - Revue manuelle requise';
    } else {
      status = 'âœ… APPROVED - Contenu appropriÃ©';
    }

    console.log(`\nğŸ¯ DÃ©cision: ${status}\n`);

    console.log('âœ… Test terminÃ© avec succÃ¨s!\n');
    console.log('ğŸ’¡ Le systÃ¨me de modÃ©ration est opÃ©rationnel.');
    console.log('ğŸ“ Vous pouvez maintenant l\'intÃ©grer dans votre API.');

  } catch (error) {
    console.error('âŒ Erreur pendant le test:', error.message);
    console.error(error.stack);
    process.exit(1);
  }
}

testModeration();
